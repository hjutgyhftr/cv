# Lichao **Shen**


English | [中文版](cv_cn.md) | [日本語](cv_jp.md)


Homepage: [red-pencil.github.io/homepage](http://red-pencil.github.io/homepage)

Email: <lichao.shen@hotmail.com>

Desgin Portfolio: [issuu.com/lichaoshen](https://issuu.com/lichaoshen/docs/portfolio3.3re)

Project Video: [youtube.com/mars](https://www.youtube.com/channel/UCuoYD-zYP5onkyi6cYbWcyg)

Gallery: [500px.com/hx470000](https://500px.com/hx470000/galleries/top)



## Fields of Interest

- **Human-Computer Interaction**
- Virtual Reality
- Mixed Reality
- Commputer Graphics
- Ubiquitous Computing
- Machine Learning

- **Human Enhancement**
- Cognitive Science
- Neuroscience
- Robotics

- **Interaction Design**
- User Experience
- User Interface
- New Media
- Industrial Design



## Education

### Master of Media Design

- Human-Computer Interaction
- Media Design

**Keio University** \| Tokyo, Japan

Sep 2015 - Mar 2018

**Pratt Institute** \| New York, USA

Jan 2017 - May 2017

**Royal College of Art & Imperial College London** \| London, UK

Sep 2016 - Dec 2016

### Bachelor of Engineering

- Industrial Design
- Mechanical Engineering

**Beihang University** \| Beijing, China

Sep 2010 - Jun 2014


## Experience

### Student Researcher

**Cyber Living Lab** \| Tokyo, Japan

Sep 2015 - Mar 2018

- [Embodied Media Project](http://www.embodiedmedia.org)
- Conducted research projects in the fields of haptic sensation, virtual reality, human augmentation, telexistence, etc.
- Develop experiments, prototypes and applications of relative fields.

### User Experience Design Intern

**Lenovo Research** \| Beijing, China

Sep 2013 - Feb 2014

- User Research Center
- Researched into user's behavior towards a variety of consumer electronics.
- Developed the preliminary design of the next generation smart devices.



## Skills

### Programming

C, C# (Unity), JavaScript, Python, Ruby, Arduino, HTML, TeX

### Engineering

Technical Drawing, Mechanical Machining

Engineering Software (SolidWorks, Pro/Engineer, AutoCAD)

### Design

Pencil Sketch, Marker Sketch, Gouache Painting, Prototyping

Graphic Software (Photoshop, Illustrator, Premiere, 3Ds Max, Rhinoceros, Grasshopper, KeyShot, V-Ray, Unity)



## Languages

**Chinese** - Native

**English** - Academic

**Japanese** - Elementary



## Publications

**Lichao Shen**, Mhd Yamen Saraji, Kai Kunze, and Kouta Minamizawa. 2018. Unconstrained Neck: Omnidirectional Observation from an Extra Robotic Neck. In *Proceedings of the 9th Augmented Human International Conference* ([AH '18](http://www.sigah.org/AH2018)). ACM, New York, NY, USA, Article 38, 2 pages. [[DOI](https://doi.org/10.1145/3174910.3174955)] [[Best Demo Award](http://www.sigah.org/AH2018/gallery)]

Mhd Yamen Saraiji, Roshan Peiris, **Lichao Shen**, Kouta Minamizawa and Susumu Tachi. 2018. Ambient: Facial Thermal Feedback in Remotely Operated Applications. In *Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems* ([CHI '18](https://chi2018.acm.org)). ACM, New York, NY, USA.



## Awards

### Best Demo Award

**2018 Augmented Human 9th International Conference (AH '18)**

Feb 2018 \| Seoul, ROK

### Design Excellent Prize

**"Gifts of Fuyang" Design Competition**

Jan 2013 \| Zhejiang, China

### Scholarship of Academic Performance

**Beihang University**

Dec 2013, Dec 2012, Dec 2011 \| Beijing, China



***

## Research Projects

### Limitless Oculus

**Visual Expansion by Animal-Inspired Visuomotor Modification**

*Master Thesis*

Humans are trapped in their senses. The human vision was relatively narrow and weak, comparing to the variety of animal superior abilities. Through my investigation, it was figured out that the human musculoskeletal systems, especially the neck, were a factor limiting the spatial range of vision. In order to help human overcome part of those limitations, I proposed the animal-inspired concept called *Limitless Oculus*. That was to substitute or modify the original visuomotor coordination of human, with a certain artificial mechanism. The mechanism, orienting the vision, was modified and designed to be programmable and customizable. The benefits aimed to promote the flexibility of the spatial orientation of vision, and hence achieve visual expansion and substitution. Besides, the concept had more possible applications with a variety of modifications and mechanisms. The method had physiological and cognitive influence, so it can not only be a tool but also change human mind. Two prototypes were presented. Then I conducted experiments to evaluate the performance of the prototypes, and prove the feasibility of the concept. The result indicated that the spatial range of vision was expanded, while the speed of the scan and response could also be augmented in a certain range.

Supervisor: Kouta Minamizawa, Sub-supervisor: Kai Kunze, Co-viewer: Ishido Nanako


### Unconstrained Neck

**Omnidirectional Observation from an Extra Robotic Neck**

*Conference Publication*

Due to the narrow range of motion of the neck and the small visual field of the eyes, the human visual sense is limited in terms of the spatial range. We address this visual limitation by proposing a programmable neck that can leverage the range of motion limits. *Unconstrained Neck*, a head-mounted robotic neck, is a substitution neck system which provides a wider range of motion enabling humans to overcome the physical constraints of the neck. Using this robotic neck, it is also possible to control the visual/motor gain, which allows the user to thus control the range and speed of his effective neck motion or visual motion.

[[Video](https://youtu.be/xq5xTcrdzXU)]


### Ambient

**Facial Thermal Feedback in Remotely Operated Applications**

*Conference Publication*

Facial thermoreception plays an important role in mediating surrounding ambient and direct feeling of temperature and touch, enhancing our subjective experience of presence. Such sensory modality has not been well explored in the field of telepresence and telexistence. We present *Ambient*, an enhanced experience of remote presence that consists of a fully facial thermal feedback system combined with the first person view of telexistence systems. Here, we present an overview of the design and implementation of Ambient, along with scenarios envisioned for social and intimate applications.


### Eye-in-Hand

**"Snail Sight", Autonomous Monocular Vision, Observe Dual Scenes Simultaneously**

In natural condition, human eyes receive almost the same visual stimulus, but that each eye registers different content could lead to new visual experience. We present a wearable device that provides two separate visual capture at the position of both hands, i.e., upper limb is utilized to control the orientation of vision. The whole system blends the two image sources avoiding the binocular rivalry, and thus enables the user to observe on two different visual information simultaneously. It improves the flexibility of vision orienting, and alters the visuomotor coordination drastically. We then examine user's adaptability to the split vision and the by-product sickness.


### Bug View

**"Being a Spider", Telexistence from Human to a Spider Robot**

Existing telepresence and telexistence research focus on humanoid and duplicating human sensation. Different from those, *Bug View* focus on mapping the human bodily consciousness to a non-human subject with totally different body schema, and here it is a spider robot. Its proposal is to provide an immersive experience of "being a spider", and smooth operation of the robot. The human-robot mapping consists of sensory mapping and kinematic mapping. We provide several feasible methods and build prototypes. Then we plan to conduct the experiment to find out the best way to provide the highest degree of presence. At least, the potential application of this kind of technology is discussed.



***

## Design Projects

### TP/Screamer

TP/Screamer (Toilet Paper Screamer), is a new eco-friendly toilet paper dispenser designed to reduce the waste of toilet paper. Every time when the sheets are pulled out over the limit (for instance, the length of 30 inches), it will let out voice warning to notify users to stop consuming more than necessity. It is good for both education and fun, and suitable for both public and home. The product is prepared for online crowdfunding.

- Designed the product individually, and fabricated an appearance prototype and a functional prototype.
- Finished branding materials including a pictured story and a promotional video.

[[Kickstarter](https://www.kickstarter.com/projects/332555363/1830982200?ref=454281&token=0cc2d35a)], [[Video](https://youtu.be/UHSKzdS4NOA)]


### Hahaki

Hahaki is postcard customizable system for modern cities. It consists of a smartphone application and a printing machine. In the app, users can choose to edit the content and pin interesting information on the postcards. After customization, users may print them at the print machines placed near the scenic area, and then post. It was selected to "City, Museum, Tokyo" Design Exhibition in Tokyo, Japan, in December 2013.

- Led a group to finish the project.
- Proposed the concept, and designed the demo, UX and UI of the mobile app and the printer.


### AERO-2013 Racing Car

AERO-2013 is the annual model of the AERO racing team, a student team. It is a racing car constructed for the Formula SAE series motor competitions. The design work is finished collaboratively based on the Formula SAE rules. Aerodynamic effect is considered and analyzed by computational fluid dynamics. It won 8th place out of 53 teams in the competition of Formula Student China 2013, and then was selected to the exhibition of Auto China 2014 by the sponsor.

- Designed the bodywork and aerodynamic kit.
- Participated in building the vehicle.


